{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":201240827,"sourceType":"kernelVersion"},{"sourceId":201240854,"sourceType":"kernelVersion"},{"sourceId":201240877,"sourceType":"kernelVersion"},{"sourceId":201240893,"sourceType":"kernelVersion"},{"sourceId":201241938,"sourceType":"kernelVersion"},{"sourceId":201241957,"sourceType":"kernelVersion"},{"sourceId":201241971,"sourceType":"kernelVersion"},{"sourceId":201241980,"sourceType":"kernelVersion"},{"sourceId":201366709,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Unfreez  Last Block --\n#-- Fold 1 --","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Install Libraries -------------------------------------------------------------------------------------------\n!pip install torchsummary\n!pip install pytorchvideo\n\nfrom IPython import display\ndisplay.clear_output()\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Imports ------------------------------------------------------------------------------------------------------\nimport torch\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torchsummary import summary\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\nimport numpy as np\nimport random\n\nimport os\nimport shutil\nimport copy\nimport pickle\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Initialize ---------------------------------------------------------------------------------------------------\nfolds_indices_file = '/kaggle/input/fight-detection-x3d-32-v2-1-create-folds/folds_indices.pkl'\ndata_file = '/kaggle/input/fight-detection-x3d-32-v2-1-create-folds/video_paths_labels.pkl'\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'device: {DEVICE}')\n\nBATCH_SIZE = 8\nNUM_EPOCHS = 50\n\nNUM_FRAMES = 32\n\nCLASS_NAMES = ['Violence','NonViolence']\nNUM_Classes = 2  \n\nFOLD_NUMBER = 1\n\ntrain_metrics_file = f'{FOLD_NUMBER}_train_metrics.pkl'\nval_metrics_file = f'{FOLD_NUMBER}_val_metrics.pkl'\ntest_metrics_file = f'{FOLD_NUMBER}_test_metrics.pkl'\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Load data ---------------------------------------------------------------------------------------------------\nwith open(folds_indices_file, 'rb') as f:\n    all_folds_indices = pickle.load(f)\n    \nwith open(data_file, 'rb') as f:\n    all_video_paths, all_labels = pickle.load(f)\n\n\nprint(f'Number of Videos: {len(all_video_paths)}\\nNumber of Labels:{len(all_labels)}')\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Define the Custom Dataset for videos -------------------------------------------------------------------------\nclass VideoDataset(Dataset):\n    def __init__(self, frames_paths, labels, transform=None):\n        self.frames_paths = frames_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.frames_paths)\n\n    def __getitem__(self, idx):\n        frames_paths = self.frames_paths[idx]\n        frames = np.load(frames_paths)  #-- videos are saved as numpy arrays of shape (NUM_FRAMES, H, W, C) --\n\n        if self.transform:\n            frames = self.transform(frames)\n\n        label = self.labels[idx]\n        return frames, label  \n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Class To Convert Frames to Tensors --------------------------------------------------------------------------\nclass ToTensor(object):\n    def __call__(self, frames):        \n        \n        #-- Convert to Tensor (C, T, H, W) --\n        frames = frames.transpose((3, 0, 1, 2))\n        frames = torch.from_numpy(frames).float()\n\n        return frames\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to evaluate the model ------------------------------------------------------------------------------\ndef calculate_metrics(model, data_loader):\n    model.eval()\n    predictions = []\n    true_labels = []\n\n    with torch.no_grad():\n        for videos, labels in data_loader:\n            videos = videos.to(DEVICE)\n            labels = labels.to(DEVICE)\n\n            outputs = model(videos)\n            _, preds = torch.max(outputs, 1)\n\n            predictions.extend(preds.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n    \n    predictions = np.array(predictions)\n    true_labels = np.array(true_labels)\n    \n    acc = accuracy_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions, average='binary')\n    recall = recall_score(true_labels, predictions, average='binary')\n    f1 = f1_score(true_labels, predictions, average='binary')\n    cm = confusion_matrix(true_labels, predictions)\n\n    return acc, precision, recall, f1, cm\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Modify X3D for finetuning ------------------------------------------------------------------------\ndef custome_X3D(num_classes):\n    #-- load X3D model --\n    model_name = 'x3d_m'\n    model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)   \n    \n     #-- Freeze all layers --\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    #-- set last layer for custome classification --\n    input_size = model.blocks[-1].proj.in_features\n    model.blocks[-1].proj = nn.Linear(in_features=input_size, out_features=num_classes)\n    \n    #-- Unfreeze Last Block --\n    for param in model.blocks[-1].parameters():\n        param.requires_grad = True\n\n    return model\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Train Model --------------------------------------------------------------------------------------\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    \n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for videos, labels in loader:\n        \n        videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(videos)       \n        \n        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n\n    loss = running_loss / len(loader)\n    accuracy = correct / total\n    return loss , accuracy\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Evaluate Model -----------------------------------------------------------------------------------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    \n    correct = 0\n    total = 0\n    running_loss = 0.0\n\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    loss = running_loss / len(loader)\n    acc = correct / total\n    return loss , acc\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Plot ACC and Loss --------------------------------------------------------------------------------------------\ndef plot_acc_and_loss(train_losses, val_losses, train_accuracies, val_accuracies):\n    \n    epochs = range(1, NUM_EPOCHS + 1)\n\n    plt.figure(figsize=(14, 5))\n\n    #-- Plot training & validation loss --\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, 'bo-', label='Train Loss')\n    plt.plot(epochs, val_losses, 'ro-', label='Val Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    #-- Plot training & validation accuracy --\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accuracies, 'bo-', label='Train Accuracy')\n    plt.plot(epochs, val_accuracies, 'ro-', label='Val Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.show()\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Run k-Fold --------------------------------------------------------------------------------------------------\nprint(f'Running Fold {FOLD_NUMBER} ==================================================') \n\n#-- set fold indices --\ntrain_idx, test_idx = all_folds_indices[FOLD_NUMBER-1]\n    \n#-- Get train and test data for this fold --\ntrain_videos = [all_video_paths[i] for i in train_idx]\ntrain_labels = [all_labels[i] for i in train_idx]\n    \ntest_videos = [all_video_paths[i] for i in test_idx]\ntest_labels = [all_labels[i] for i in test_idx]   \n    \n#-- Split train data into train and validation sets (70% train, 30% validation) --\ntrain_videos, val_videos, train_labels, val_labels = train_test_split(train_videos,\n                                                                          train_labels,\n                                                                          test_size=0.3,\n                                                                          random_state=42)    \nprint('Dataset Size: '\n        f'\\tTrain = {len(train_videos)}'\n        f'\\tVal = {len(val_videos)}'\n        f'\\tTest = {len(test_videos)}')\n    \n#-- Create datasets --\ntrain_dataset = VideoDataset(train_videos,train_labels, transforms.Compose([ToTensor()]))\nval_dataset = VideoDataset(val_videos,val_labels, transforms.Compose([ToTensor()]))\ntest_dataset = VideoDataset(test_videos,test_labels, transforms.Compose([ToTensor()]))\n\n#-- Create dataloaders --\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n#-- Initialize model --\nmodel = custome_X3D(NUM_Classes).to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n    \n#-- Train model --\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\nbest_model = None\nbest_acc = 0\nbest_epoch =0\n\nfor epoch in range(NUM_EPOCHS):        \n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)    \n\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n\n    if val_acc> best_acc:\n        best_acc = val_acc\n        best_model = copy.deepcopy(model)\n        best_epoch = epoch          \n\n\n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, '\n            f'Train Loss: {train_loss:.4f}, Train ACC: {train_acc:.4f}, '\n            f'Val Loss: {val_loss:.4f}, Val ACC: {val_acc:.4f}')\n\nlast_model = copy.deepcopy(model)    \n    \n#-- plot ACC and LOSS --\nplot_acc_and_loss(train_losses, val_losses, train_accuracies, val_accuracies)\n    \n#-- Calculate metrics for train, val and test data --\ntrain_acc, train_precision, train_recall, train_f1, train_cm = calculate_metrics(best_model, train_loader)\nval_acc, val_precision, val_recall, val_f1, val_cm = calculate_metrics(best_model, val_loader)\ntest_acc, test_precision, test_recall, test_f1, test_cm = calculate_metrics(best_model, test_loader)\n    \n# -- Print metrics --\nprint(f'Train: .......................\\n'\n        f'Accuracy: {train_acc:.4f}\\n'\n        f'Precision: {train_precision:.4f}\\n'\n        f'Recall: {train_recall:.4f}\\n'\n        f'F1 Score: {train_f1:.4f}')\n    \nprint(f'Val: .......................\\n'\n        f'Accuracy: {val_acc:.4f}\\n'\n        f'Precision: {val_precision:.4f}\\n'\n        f'Recall: {val_recall:.4f}\\n'\n        f'F1 Score: {val_f1:.4f}')\n    \nprint(f'Test: .......................\\n'\n        f'Accuracy: {test_acc:.4f}\\n'\n        f'Precision: {test_precision:.4f}\\n'\n        f'Recall: {test_recall:.4f}\\n'\n        f'F1 Score: {test_f1:.4f}')   \n    \n    \n\n#-- Plot Train confusion matrix --\nplt.figure(figsize=(4, 3))\nsns.heatmap(train_cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Fight', 'Normal'], yticklabels=['Fight', 'Normal'],\n            cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Train Confusion Matrix for Fold {FOLD_NUMBER}')\nplt.show()\n    \n#-- Plot Val confusion matrix --\nplt.figure(figsize=(4, 3))\nsns.heatmap(val_cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Fight', 'Normal'], yticklabels=['Fight', 'Normal'],\n            cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Val Confusion Matrix for Fold {FOLD_NUMBER}')\nplt.show()\n    \n#-- Plot Test confusion matrix --\nplt.figure(figsize=(4, 3))\nsns.heatmap(test_cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Fight', 'Normal'], yticklabels=['Fight', 'Normal'],\n            cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Test Confusion Matrix for Fold {FOLD_NUMBER}')\nplt.show()\n    \n#-- Save the metrics --\ntrain_metrics = {\n    'train_acc': train_acc,\n    'train_precision': train_precision,\n    'train_recall': train_recall,\n    'train_f1': train_f1,\n    'train_cm': train_cm\n}\n\nval_metrics = {\n    'val_acc': val_acc,\n    'val_precision': val_precision,\n    'val_recall': val_recall,\n    'val_f1': val_f1,\n    'val_cm': val_cm\n}\n\ntest_metrics = {\n    'test_acc': test_acc,\n    'test_precision': test_precision,\n    'test_recall': test_recall,\n    'test_f1': test_f1,\n    'test_cm': test_cm\n}\n\nwith open(train_metrics_file, 'wb') as f:\n    pickle.dump(train_metrics_file, f)\n    \nwith open(val_metrics_file, 'wb') as f:\n    pickle.dump(val_metrics_file, f)\n    \nwith open(test_metrics_file, 'wb') as f:\n    pickle.dump(test_metrics_file, f)\n    \n#----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Save model ---------------------------------------------------------------------------------------------------\ntorch.save(last_model.state_dict(), f'{FOLD_NUMBER}_last.pth')\ntorch.save(best_model.state_dict(), f'{FOLD_NUMBER}_best.pth')\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}