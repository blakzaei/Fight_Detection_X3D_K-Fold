{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":397693,"sourceType":"datasetVersion","datasetId":176381}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Sample 32 Frames --\n#-- Resize  --\n#-- Augmentation: Brightness --","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Imports ------------------------------------------------------------------------------------------------------\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport random\n\nimport os\nimport shutil\nimport copy\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Initialize ---------------------------------------------------------------------------------------------------\nds_input_path = '/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/'\n\nNUM_FRAMES = 32\nFRAME_W = 256\nFRAME_H = 256\n\nCLASS_NAMES = ['Violence', 'NonViolence']\n\nORIGIN = True\nNOISY = False\nBRIGHT = False\nNOISY_BRIGHT = False\nBLUR = False\n\nif ORIGIN:\n    ds_result_path = '/kaggle/working/ds_origin'\n    \nif NOISY:\n    ds_result_path = '/kaggle/working/ds_noisy'\n\nif BRIGHT:   \n    ds_result_path = '/kaggle/working/ds_birght'\n\nif NOISY_BRIGHT:\n    ds_result_path = '/kaggle/working/ds_noisy_birght'\n\nif BLUR:\n    ds_result_path = '/kaggle/working/ds_blur'\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Select Samples for each Augmentation -------------------------------------------------------------------------\nif not ORIGIN:\n    random.seed(42)\n    \n    violence_files_list = os.listdir('/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/Violence')\n    non_violence_files_list = os.listdir('/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence')\n\n    violence_files_list = sorted(violence_files_list)\n    non_violence_files_list = sorted(non_violence_files_list)\n\n    num_items = 250\n\n    v_noisy = random.choices(violence_files_list, k=num_items)\n    v_bright = random.choices(violence_files_list, k=num_items)\n    v_noisy_bright = random.choices(violence_files_list, k=num_items)\n    v_blur = random.choices(violence_files_list, k=num_items)\n\n    nv_noisy = random.choices(non_violence_files_list, k=num_items)\n    nv_bright = random.choices(non_violence_files_list, k=num_items)\n    nv_noisy_bright = random.choices(non_violence_files_list, k=num_items)\n    nv_blur = random.choices(non_violence_files_list, k=num_items)\n    \n    random.seed(None)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Add Noise ----------------------------------------------------------------------------------------\ndef add_noise(image, factor):\n    noise = np.random.normal(0, factor, image.shape).astype(np.uint8)\n    noisy_image = cv2.add(image, noise)\n    return noisy_image\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Change Brightness --------------------------------------------------------------------------------\ndef adjust_brightness(image, factor):\n    return cv2.convertScaleAbs(image, alpha=factor, beta=0)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Add Noise and Change Brightness ------------------------------------------------------------------\ndef apply_noise_and_brightness(image, nois_factor, bright_factor):\n    noisy_image = add_noise(image, nois_factor)     \n    return adjust_brightness(noisy_image, bright_factor)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Funvtion to Apply Blur ---------------------------------------------------------------------------------------\ndef apply_blur(image, kernel_size=(7, 7)):    \n    return cv2.GaussianBlur(image, kernel_size, 0)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Normalize Pixel Values to the range [0, 1] -------------------------------------------------------\ndef normalize_image(image):\n    return image.astype(np.float32) / 255.0\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Ù‘Function to sample frames ------------------------------------------------------------------------------------\ndef sample_frames(frames, num_samples):    \n    return random.sample(range(len(frames)), num_samples)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- function to plot Sampled Videos ------------------------------------------------------------------------------\ndef plot_samples(original_samples, noisy_samples, bright_samples, noisy_bright_samples, blur_samples, num_samples_to_plot=5):\n    fig, axes = plt.subplots(num_samples_to_plot, 5, figsize=(10, num_samples_to_plot * 2))\n\n    for i in range(num_samples_to_plot):\n        #-- Original Samples --\n        axes[i, 0].imshow(original_samples[i])\n        axes[i, 0].set_title(f'Original {i + 1}')\n        axes[i, 0].axis('off')\n\n        #-- Noisy Samples --\n        axes[i, 1].imshow(noisy_samples[i])\n        axes[i, 1].set_title(f'Noisy {i + 1}')\n        axes[i, 1].axis('off')\n\n        #-- Bright Samples --\n        axes[i, 2].imshow(bright_samples[i])\n        axes[i, 2].set_title(f'Dark {i + 1}')\n        axes[i, 2].axis('off')\n\n        #-- noisy and bright Samples --\n        axes[i, 3].imshow(noisy_bright_samples[i])\n        axes[i, 3].set_title(f'Noisy and Dark {i + 1}')\n        axes[i, 3].axis('off')\n        \n        #-- Blur Samples --\n        axes[i, 4].imshow(blur_samples[i])\n        axes[i, 4].set_title(f'Blur {i + 1}')\n        axes[i, 4].axis('off')\n        \n        \n\n    plt.tight_layout()\n    plt.show()\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Process a single video and return sampled frames as numpy arrays --------------------------------\ndef process_video(video_path, num_frames=NUM_FRAMES, resize=(FRAME_W, FRAME_H)):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        frame_resized = cv2.resize(frame, resize)\n        frames.append(frame_resized)\n\n    cap.release()\n\n    #-- Sample frames --\n    if ORIGIN:\n        sampled_indices_original = sample_frames(frames, num_frames)\n    if NOISY:\n        sampled_indices_noisy = sample_frames(frames, num_frames)\n    if BRIGHT:\n        sampled_indices_bright = sample_frames(frames, num_frames)\n    if NOISY_BRIGHT:\n        sampled_indices_brihgt_and_noisy = sample_frames(frames, num_frames)\n    if BLUR:\n        sampled_indices_blur = sample_frames(frames, num_frames)\n\n    #-- Create arrays to store the samples --\n    original_samples = np.zeros((num_frames, FRAME_W, FRAME_H, 3), dtype=np.float32)\n    noisy_samples = np.zeros((num_frames, FRAME_W, FRAME_H, 3), dtype=np.float32)\n    bright_samples = np.zeros((num_frames, FRAME_W, FRAME_H, 3), dtype=np.float32)\n    bright_and_noisy_samples = np.zeros((num_frames, FRAME_W, FRAME_H, 3), dtype=np.float32)\n    blur_samples = np.zeros((num_frames, FRAME_W, FRAME_H, 3), dtype=np.float32)\n\n    if NOISY or BRIGHT or NOISY_BRIGHT:\n        noise_factor = random.randint(3, 8)    \n        bright_factor = random.uniform(0.2, 0.7)    \n        print(f'noise_factor: {noise_factor}\\nbright_factor: {bright_factor}')\n    \n    for i in range(num_frames):\n        #-- Original Frame --\n        if ORIGIN:\n            original_samples[i] = normalize_image(frames[sampled_indices_original[i]])\n\n        #-- Noisy Frame --    \n        if NOISY:\n            noisy_samples[i] = normalize_image(add_noise(frames[sampled_indices_noisy[i]], noise_factor))\n\n        #-- Bright Frame --   \n        if BRIGHT:\n            bright_samples[i] = normalize_image(adjust_brightness(frames[sampled_indices_bright[i]], bright_factor))\n\n        #-- Nosiy and Brightness Frame --        \n        if NOISY_BRIGHT:\n            bright_and_noisy_samples[i] = normalize_image(adjust_brightness(add_noise(frames[sampled_indices_brihgt_and_noisy[i]],\n                                                                          noise_factor),\n                                                                bright_factor))\n        #-- Blur Frame --\n        if BLUR:\n            blur_samples[i] = normalize_image(apply_blur(frames[sampled_indices_blur[i]]))\n\n    return original_samples, noisy_samples, bright_samples, bright_and_noisy_samples, blur_samples\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Preprocess All Videos in DS ----------------------------------------------------------------------\ndef process_all_videos(video_dir, output_dir, num_frames=NUM_FRAMES):   \n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    for label in CLASS_NAMES:\n        label_dir = os.path.join(video_dir, label)\n        output_label_dir = os.path.join(output_dir, label)\n        if not os.path.exists(output_label_dir):\n            os.makedirs(output_label_dir)\n\n        if ORIGIN:\n            video_file_list = os.listdir(label_dir)\n        \n        if NOISY:\n            if label == 'Violence':\n                video_file_list = v_noisy\n            else:\n                video_file_list = nv_noisy\n        \n        if BRIGHT:\n            if label == 'Violence':\n                video_file_list = v_bright\n            else:\n                video_file_list = nv_bright\n        \n        if NOISY_BRIGHT:\n            if label == 'Violence':\n                video_file_list = v_noisy_bright\n            else:\n                video_file_list = nv_noisy_bright\n        \n        if BLUR:\n            if label == 'Violence':\n                video_file_list = v_blur\n            else:\n                video_file_list = nv_blur            \n        \n        for video_file in video_file_list:            \n            video_path = os.path.join(label_dir, video_file)\n            original_samples, noisy_samples, bright_samples, bright_and_noisy_samples, blur_samples = process_video(video_path,\n                                                                                                                    num_frames)\n            \n            #plot_samples(original_samples, noisy_samples, bright_samples, bright_and_noisy_samples, blur_samples)\n                        \n            #-- Save samples for each video --  \n            if ORIGIN:\n                np.save(os.path.join(output_label_dir, f\"original_{video_file.replace('.mp4', '.npy')}\"), original_samples)\n            if NOISY:\n                np.save(os.path.join(output_label_dir, f\"noisy_{video_file.replace('.mp4', '.npy')}\"), noisy_samples)\n            if BRIGHT:\n                np.save(os.path.join(output_label_dir, f\"bright_{video_file.replace('.mp4', '.npy')}\"), bright_samples)\n            if NOISY_BRIGHT:\n                np.save(os.path.join(output_label_dir, f\"bright_noisy_{video_file.replace('.mp4', '.npy')}\"), bright_and_noisy_samples)\n            if BLUR:\n                np.save(os.path.join(output_label_dir, f\"blur_{video_file.replace('.mp4', '.npy')}\"), blur_samples)\n                                   \n            break\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_all_videos(ds_input_path, ds_result_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Zip Data -----------------------------------------------------------------------------------------------------\nif ORIGIN:\n    ds_zip_file = '/kaggle/working/data_origin'\n\nif NOISY:\n    ds_zip_file = '/kaggle/working/data_noisy'\n\nif BRIGHT:\n    ds_zip_file = '/kaggle/working/data_bright'\n\nif NOISY_BRIGHT:\n    ds_zip_file = '/kaggle/working/data_noisy_bright'\n\nif BLUR:\n    ds_zip_file = '/kaggle/working/data_blur'\n\nshutil.make_archive(ds_zip_file, 'zip', ds_result_path)\nshutil.rmtree(ds_result_path)\n#-------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}